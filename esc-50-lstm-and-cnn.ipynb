{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":142598,"sourceType":"datasetVersion","datasetId":3151},{"sourceId":9893078,"sourceType":"datasetVersion","datasetId":6076148},{"sourceId":10071204,"sourceType":"datasetVersion","datasetId":6207551}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ESC 50\nData preparation (spectogram creation) is loosely copied from https://www.kaggle.com/code/doofensmirtz/85-validation-accuracy-tensorflow","metadata":{}},{"cell_type":"markdown","source":"## Importing Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport librosa\nimport librosa.display\nfrom tqdm import tqdm\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.tensorboard import SummaryWriter\nimport torch.nn.functional as F\nimport os\nfrom torchinfo import summary\nimport gc\nfrom sklearn.metrics import f1_score\nfrom tensorboard.plugins.hparams import api as hp\nimport optuna\n\nfrom IPython.display import display\n%matplotlib inline\n%load_ext tensorboard","metadata":{"id":"lbJSMIhi34sC","execution":{"iopub.status.busy":"2024-12-18T23:32:59.970608Z","iopub.execute_input":"2024-12-18T23:32:59.970961Z","iopub.status.idle":"2024-12-18T23:33:13.107052Z","shell.execute_reply.started":"2024-12-18T23:32:59.970932Z","shell.execute_reply":"2024-12-18T23:33:13.106363Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"MODE = 'RUN'\nAUGUMENTATION = True","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Loading and Preprocessing","metadata":{}},{"cell_type":"code","source":"CSV_FILE_PATH = \"../input/environmental-sound-classification-50/esc50.csv\"  # path of csv file\nDATA_PATH = \"../input/environmental-sound-classification-50/audio/audio/44100/\" # path to folder containing audio files\nPRIVATE_DATA_PATH = \"../input/esc50-private/\" # path to folder containing audio files","metadata":{"id":"6Xy1fe9W4apR","execution":{"iopub.status.busy":"2024-12-18T23:33:13.108049Z","iopub.execute_input":"2024-12-18T23:33:13.108555Z","iopub.status.idle":"2024-12-18T23:33:13.112024Z","shell.execute_reply.started":"2024-12-18T23:33:13.108519Z","shell.execute_reply":"2024-12-18T23:33:13.111223Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#reading the csv file\ndf = pd.read_csv(CSV_FILE_PATH).drop(['esc10','src_file','take'], axis=1)\ndf['filepath'] = DATA_PATH + df['filename']\ndisplay(df)\n\nclasses = df['category'].unique()\nprint(classes)\n\nclass_dict = {i:x for x,i in enumerate(classes)}\nprint(class_dict)\n\ndf['target'] = df['category'].map(class_dict)\ndisplay(df)\n","metadata":{"id":"mBR823ct8C1p","outputId":"56ad2679-4b53-4bcb-b354-295e6b0772fc","execution":{"iopub.status.busy":"2024-12-18T23:33:13.113596Z","iopub.execute_input":"2024-12-18T23:33:13.113864Z","iopub.status.idle":"2024-12-18T23:33:13.184864Z","shell.execute_reply.started":"2024-12-18T23:33:13.113843Z","shell.execute_reply":"2024-12-18T23:33:13.183966Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Visualization","metadata":{}},{"cell_type":"markdown","source":"[](http://)","metadata":{}},{"cell_type":"code","source":"sample_df = df.drop_duplicates(subset=['target'])\nprint(\"Sample df:\")\ndisplay(sample_df)\n\ndef visualize_data():\n    signals = {}\n    mel_spectrograms = {}\n\n    for row in tqdm(sample_df.iterrows()):  # every row will be like [[index], [filename , target , category]]\n        signal , rate = librosa.load(DATA_PATH+ row[1][0])\n        signals[row[1][2]] = signal    # row[1][2] will be the category of that signal. eg. signal[\"dog\"] = signal of dog sound\n\n        mel_spec = librosa.feature.melspectrogram(y=signal , sr=rate ,  n_fft=2048, hop_length=512)\n        mel_spec = librosa.power_to_db(mel_spec, ref=np.max)  #visualizing mel_spectrogram directly gives black image. So, coverting from power_to_db is required\n        mel_spectrograms[row[1][2]] = mel_spec\n\n    # plot signals\n    fig , axes = plt.subplots(nrows=25 , ncols=2 , sharex =False ,sharey=True,\n                             figsize=(40,20))\n    fig.suptitle('Time series',size=15)\n    i=0\n    for x in range(25):\n        for y in range(2):\n            axes[x,y].set_title(list(signals.keys())[i])\n            axes[x,y].plot(list(signals.values())[i])\n            axes[x,y].get_xaxis().set_visible(False)\n            axes[x,y].get_yaxis().set_visible(False)\n            i +=1\n\n    plt.show()\n    plt.close(fig)\n    \n    # plot mel spectograms\n    fig , axes = plt.subplots(nrows=25 , ncols=2 , sharex =False ,sharey=True,\n                             figsize=(100,100))\n    fig.suptitle('Mel spectograms',size=15)\n    i=0\n    for x in range(25):\n        for y in range(2):\n            axes[x,y].set_title(list(mel_spectrograms.keys())[i])\n            axes[x,y].imshow(list(mel_spectrograms.values())[i], cmap=None,interpolation='nearest')\n            axes[x,y].get_xaxis().set_visible(False)\n            axes[x,y].get_yaxis().set_visible(False)\n            i+=1\n\n    plt.show()\n    plt.close(fig)\n    \nvisualize_data()","metadata":{"id":"-wpKTTerHa6Q","outputId":"fdadbbeb-d200-4956-92e1-e579da39dc6b","execution":{"iopub.status.busy":"2024-12-18T23:33:13.185981Z","iopub.execute_input":"2024-12-18T23:33:13.186203Z","iopub.status.idle":"2024-12-18T23:33:35.419678Z","shell.execute_reply.started":"2024-12-18T23:33:13.186184Z","shell.execute_reply":"2024-12-18T23:33:35.418359Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data augumentation","metadata":{}},{"cell_type":"code","source":"def add_noise(data):\n    \"\"\"\n    Add noise to the audio signal to simulate different noise conditions.\n    \"\"\"\n    noise = np.random.normal(0, 0.007, len(data))\n    audio_noisy = data + noise\n    return audio_noisy\n\n\ndef pitch_shifting(data):\n    \"\"\"\n    Change the pitch of the audio signal by shifting it up or down.\n    \"\"\"\n    bins_per_octave = 12\n    pitch_pm = 2\n    pitch_change = pitch_pm * 2 * (np.random.uniform())\n    data = librosa.effects.pitch_shift(\n        data.astype(\"float64\"),\n        sr=16000,\n        n_steps=pitch_change,\n        bins_per_octave=bins_per_octave,\n    )\n    return data\n\n\ndef random_shift(data):\n    \"\"\"\n    Change the position of the audio signal in time by shifting it forwards or backwards.\n    \"\"\"\n    timeshift_fac = 0.2 * 2 * (np.random.uniform() - 0.5)  # up to 20% of length\n    start = int(data.shape[0] * timeshift_fac)\n    if start > 0:\n        data = np.pad(data, (start, 0), mode=\"constant\")[0 : data.shape[0]]\n    else:\n        data = np.pad(data, (0, -start), mode=\"constant\")[0 : data.shape[0]]\n    return data\n\n\ndef volume_scaling(data):\n    \"\"\"\n    Change the volume of the audio signal by scaling it up or down.\n    \"\"\"\n    dyn_change = np.random.uniform(low=1.5, high=2.5)\n    data = data * dyn_change\n    return data\n\n\ndef time_stretching(data, rate=1.5):\n    \"\"\"\n    Change the duration of the audio signal by speeding it up or slowing it down.\n    \"\"\"\n    input_length = len(data)\n    stretching = data.copy()\n    stretching = librosa.effects.time_stretch(y=stretching, rate=rate)\n\n    if len(stretching) > input_length:\n        stretching = stretching[:input_length]\n    else:\n        stretching = np.pad(\n            stretching, (0, max(0, input_length - len(stretching))), \"constant\"\n        )\n    return stretching","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T23:33:35.420976Z","iopub.execute_input":"2024-12-18T23:33:35.421920Z","iopub.status.idle":"2024-12-18T23:33:35.431411Z","shell.execute_reply.started":"2024-12-18T23:33:35.421875Z","shell.execute_reply":"2024-12-18T23:33:35.430522Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Prepare datasets","metadata":{}},{"cell_type":"code","source":"# load private data\nprivate_labels = []\nprivate_mel_spectrograms = []\nsignals = []  # Store signals for plotting\n\nfor file in tqdm(os.listdir(PRIVATE_DATA_PATH)):\n    class_name = file[:-5]\n    assert class_name in class_dict.keys()\n    signal, rate = librosa.load(os.path.join(PRIVATE_DATA_PATH, file), sr=22050, duration=5.0)\n    mel_spec = librosa.feature.melspectrogram(y=signal, sr=rate, n_fft=2048, hop_length=512)\n    mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n    private_mel_spectrograms.append(mel_spec)\n    # cut X.wav from name\n    private_labels.append(class_dict[class_name])\n    signals.append((signal, rate))\n\n# Find max length in time dimension of spectrograms\nmax_time_steps = max([mel_spec.shape[1] for mel_spec in private_mel_spectrograms])\n\n# Pad each spectrogram to have the same time dimension\npadded_private_mel_spectrograms = []\nfor mel_spec in private_mel_spectrograms:\n    pad_width = max_time_steps - mel_spec.shape[1]\n    if pad_width > 0:\n        mel_spec = np.pad(mel_spec, ((0, 0), (0, pad_width)), mode='constant')\n    padded_private_mel_spectrograms.append(mel_spec)\n\nprivate_mel_spectrograms = padded_private_mel_spectrograms\n\n# Plot one signal and spectrogram per class\nunique_classes = list(set(private_labels))\nplotted_classes = set()\n\nplt.figure(figsize=(12, 8))\nfor idx, (label, signal_data) in enumerate(zip(private_labels, signals)):\n    if label not in plotted_classes:\n        plotted_classes.add(label)\n        \n        signal, rate = signal_data\n        mel_spec = private_mel_spectrograms[idx]\n        \n        # Plot waveform\n        plt.subplot(2, 1, 1)\n        plt.title(f\"Waveform of class {label}\")\n        librosa.display.waveshow(signal, sr=rate, alpha=0.75)\n        plt.xlabel(\"Time (s)\")\n        plt.ylabel(\"Amplitude\")\n        \n        # Plot spectrogram\n        plt.subplot(2, 1, 2)\n        plt.title(f\"Spectrogram of class {label}\")\n        librosa.display.specshow(mel_spec, sr=rate, hop_length=512, x_axis='time', y_axis='mel', cmap='viridis')\n        plt.colorbar(format='%+2.0f dB')\n        plt.xlabel(\"Time (s)\")\n        plt.ylabel(\"Mel Frequency\")\n        \n        plt.tight_layout()\n        plt.show()\n        \n        # Break if all unique classes are plotted\n        if len(plotted_classes) == len(unique_classes):\n            break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T23:33:35.432217Z","iopub.execute_input":"2024-12-18T23:33:35.432420Z","iopub.status.idle":"2024-12-18T23:33:53.584569Z","shell.execute_reply.started":"2024-12-18T23:33:35.432402Z","shell.execute_reply":"2024-12-18T23:33:53.583773Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mel_spectrograms = [[], [], [], [], []]\nlabels = [[], [], [], [], []]\n\n# Compute mel spectrograms for all audio files\nfor index, row in tqdm(df.iterrows(), total=df.shape[0]):\n    # Load audio file\n    signal, rate = librosa.load(row['filepath'], sr=22050, duration=5.0)\n    if AUGUMENTATION:\n        noise_data = add_noise(signal)\n        time_stretching_data = time_stretching(data=signal, rate=1.5)\n        random_shift_data = random_shift(signal)\n        volume_scale_data = volume_scaling(signal)\n        samples = [signal, noise_data, time_stretching_data, random_shift_data, volume_scale_data]\n    else:\n        samples = [signal]\n    \n    for sample in samples:\n        # Compute mel spectrogram\n        mel_spec = librosa.feature.melspectrogram(y=sample, sr=rate, n_fft=2048, hop_length=512)\n        mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n        mel_spectrograms[row['fold'] - 1].append(mel_spec)\n        labels[row['fold'] - 1].append(row['target'])\n\ntest_x = np.array(mel_spectrograms[0])\ntest_y = np.array(labels[0])\nprivate_test_x = np.array(private_mel_spectrograms)\nprivate_test_y = np.array(private_labels)\nval_x = np.array(mel_spectrograms[1])\nval_y = np.array(labels[1])\ntrain_x = np.array(mel_spectrograms[2] + mel_spectrograms[3] + mel_spectrograms[4])\ntrain_y = np.array(labels[2] + labels[3] + labels[4])\nfinal_train_x = np.array(mel_spectrograms[0] + mel_spectrograms[2] + mel_spectrograms[3] + mel_spectrograms[4])\nfinal_train_y = np.array(labels[0] + labels[2] + labels[3] + labels[4])\n\nprint(private_test_x.shape, private_test_y.shape)\nprint(test_x.shape, test_y.shape)\nprint(val_x.shape, val_y.shape)\nprint(train_x.shape, train_y.shape)\nprint(final_train_x.shape, final_train_y.shape)","metadata":{"execution":{"iopub.status.busy":"2024-12-18T23:39:42.196594Z","iopub.execute_input":"2024-12-18T23:39:42.196953Z","iopub.status.idle":"2024-12-18T23:40:49.339763Z","shell.execute_reply.started":"2024-12-18T23:39:42.196928Z","shell.execute_reply":"2024-12-18T23:40:49.339044Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# LSTM Hyperparameters\nHP_LSTM_HIDDEN_SIZE = hp.HParam('lstm_hidden_size', hp.IntInterval(1, 4096))\nHP_LSTM_NUM_LAYERS = hp.HParam('lstm_num_layers', hp.IntInterval(1, 6))\nHP_LSTM_DROPOUT = hp.HParam('lstm_dropout', hp.RealInterval(0.0, 0.7))\n\n# CNN Hyperparameters\nHP_CNN_CONV1_KERNEL_SIZE_X = hp.HParam('cnn_conv1_kernel_size_x', hp.IntInterval(2, 32))\nHP_CNN_CONV1_KERNEL_SIZE_Y = hp.HParam('cnn_conv1_kernel_size_y', hp.IntInterval(2, 32))\nHP_CNN_POOL1_KERNEL_SIZE_X = hp.HParam('cnn_pool1_kernel_size_x', hp.IntInterval(2, 8))\nHP_CNN_POOL1_KERNEL_SIZE_Y = hp.HParam('cnn_pool1_kernel_size_y', hp.IntInterval(1, 8))\nHP_CNN_CONV2_KERNEL_SIZE_X = hp.HParam('cnn_conv2_kernel_size_x', hp.IntInterval(2, 8))\nHP_CNN_CONV2_KERNEL_SIZE_Y = hp.HParam('cnn_conv2_kernel_size_y', hp.IntInterval(1, 8))\nHP_CNN_POOL2_KERNEL_SIZE_X = hp.HParam('cnn_pool2_kernel_size_x', hp.IntInterval(1, 4))\nHP_CNN_POOL2_KERNEL_SIZE_Y = hp.HParam('cnn_pool2_kernel_size_y', hp.IntInterval(1, 4))\nHP_CNN_HIDDEN_SIZE = hp.HParam('cnn_hidden_size', hp.IntInterval(1, 8192))\nHP_CNN_DROPOUT_CONV1_RATE = hp.HParam('cnn_dropout_conv1_rate', hp.RealInterval(0.0, 0.7))\nHP_CNN_DROPOUT_CONV2_RATE = hp.HParam('cnn_dropout_conv2_rate', hp.RealInterval(0.0, 0.7))\nHP_CNN_DROPOUT_FC_RATE = hp.HParam('cnn_dropout_fc_rate', hp.RealInterval(0.0, 0.7))\nHP_CNN_NUM_CHANNELS = hp.HParam('cnn_num_channels', hp.IntInterval(2, 128))\n\n# LSTMAttentionCNN Hyperparameters\nHP_LSTMCNN_HIDDEN_SIZE = hp.HParam('lstmcnn_hidden_size', hp.IntInterval(1, 1024))\nHP_LSTMCNN_NUM_LAYERS = hp.HParam('lstmcnn_num_layers', hp.IntInterval(1, 2))\nHP_LSTMCNN_NUM_HEADS = hp.HParam('lstmcnn_num_heads', hp.IntInterval(1, 16))\nHP_LSTMCNN_CONV1_KERNEL_SIZE = hp.HParam('lstmcnn_conv1_kernel_size', hp.IntInterval(2, 32))\nHP_LSTMCNN_CONV2_KERNEL_SIZE = hp.HParam('lstmcnn_conv2_kernel_size', hp.IntInterval(2, 16))\nHP_LSTMCNN_POOL1_KERNEL_SIZE = hp.HParam('lstmcnn_pool1_kernel_size', hp.IntInterval(2, 8))\nHP_LSTMCNN_POOL2_KERNEL_SIZE = hp.HParam('lstmcnn_pool2_kernel_size', hp.IntInterval(2, 8))\nHP_LSTMCNN_DROPOUT_LSTM_RATE = hp.HParam('lstmcnn_dropout_lstm_rate', hp.RealInterval(0.0, 0.7))\nHP_LSTMCNN_DROPOUT_ATTN_RATE = hp.HParam('lstmcnn_dropout_attn_rate', hp.RealInterval(0.0, 0.7))\nHP_LSTMCNN_DROPOUT_CONV1_RATE = hp.HParam('lstmcnn_dropout_conv1_rate', hp.RealInterval(0.0, 0.7))\nHP_LSTMCNN_DROPOUT_CONV2_RATE = hp.HParam('lstmcnn_dropout_conv2_rate', hp.RealInterval(0.0, 0.7))\nHP_LSTMCNN_DROPOUT_FC_RATE = hp.HParam('lstmcnn_dropout_fc_rate', hp.RealInterval(0.0, 0.7))\nHP_LSTMCNN_CNN_OUT_CHANNELS = hp.HParam('lstmcnn_cnn_out_channels', hp.IntInterval(2, 128))\nHP_LSTMCNN_FC_HIDDEN_SIZE = hp.HParam('lstmcnn_fc_hidden_size', hp.IntInterval(16, 8192))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-12-18T23:33:53.621838Z","iopub.status.idle":"2024-12-18T23:33:53.622089Z","shell.execute_reply":"2024-12-18T23:33:53.621986Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Initialize hyperparameters","metadata":{}},{"cell_type":"code","source":"\n\n'''\nBest hyperparameters for LSTMCNN:\n{\n'hidden_size': 2654,\n'num_layers': 1,\n'num_heads': 6,\n'conv1_kernel_size': 15,\n'conv2_kernel_size': 6,\n'pool1_kernel_size': 2,\n'pool2_kernel_size': 4,\n'dropout_lstm_rate': 0.6085469197951502,\n'dropout_attn_rate': 0.18886736927751804,\n'dropout_conv1_rate': 0.3129152390777908,\n'dropout_conv2_rate': 0.30551219428129983,\n'dropout_fc_rate': 0.5657045077939624,\n'cnn_out_channels': 38,\n'fc_hidden_size': 571,\n'learning_rate': 0.0001124180393666018,\n'weight_decay': 0.0014236035034121022\n}\nVal Acc: 0.4775, Val F1: 0.4626\n'''\n\n'''\nBest hyperparameters for CNN:\n{\n'conv1_kernel_size_x': 27,\n'conv1_kernel_size_y': 15,\n'conv2_kernel_size_x': 2,\n'conv2_kernel_size_y': 3,\n'pool1_kernel_size_x': 5,\n'pool1_kernel_size_y': 7,\n'pool2_kernel_size_x': 3,\n'pool2_kernel_size_y': 2,\n'hidden_size': 6299,\n'dropout_conv1_rate': 0.011614705225163842,\n'dropout_conv2_rate': 0.02490196806259639,\n'dropout_fc_rate': 0.5574060256228773,\n'num_channels': 100,\n'learning_rate': 0.0001182121358018495,\n'weight_decay': 0.000978912231799175\n}\nVal Acc: 0.5175, Val F1: 0.5078\n'''\n\n'''\n{\n'conv1_kernel_size_x': 14,\n'conv1_kernel_size_y': 6,\n'conv2_kernel_size_x': 2,\n'conv2_kernel_size_y': 5,\n'pool1_kernel_size_x': 5,\n'pool1_kernel_size_y': 8,\n'pool2_kernel_size_x': 3,\n'pool2_kernel_size_y': 4,\n'hidden_size': 6090,\n'dropout_conv1_rate': 0.007385545905756266,\n'dropout_conv2_rate': 0.3713678969520621,\n'dropout_fc_rate': 0.5753897102755045,\n'num_channels': 90,\n'learning_rate': 0.00015169134548009995,\n'weight_decay': 0.009258909446463159\n}\nVal Acc: 0.6030, Val F1: 0.5895\n'''\n\ndefault_hparams = {\n    HP_CNN_CONV1_KERNEL_SIZE_X: 14,\n    HP_CNN_CONV1_KERNEL_SIZE_Y: 6,\n    HP_CNN_POOL1_KERNEL_SIZE_X: 2,\n    HP_CNN_POOL1_KERNEL_SIZE_Y: 5,\n    HP_CNN_CONV2_KERNEL_SIZE_X: 5,\n    HP_CNN_CONV2_KERNEL_SIZE_Y: 8,\n    HP_CNN_POOL2_KERNEL_SIZE_X: 3,\n    HP_CNN_POOL2_KERNEL_SIZE_Y: 4,\n    HP_CNN_HIDDEN_SIZE: 6090,\n    HP_CNN_DROPOUT_CONV1_RATE: 0.007385545905756266,\n    HP_CNN_DROPOUT_CONV2_RATE: 0.3713678969520621,\n    HP_CNN_DROPOUT_FC_RATE: 0.5753897102755045,\n    HP_CNN_NUM_CHANNELS: 90,\n\n    HP_LSTMCNN_HIDDEN_SIZE: 3000,\n    HP_LSTMCNN_NUM_LAYERS: 1,\n    HP_LSTMCNN_NUM_HEADS: 6,\n    HP_LSTMCNN_CONV1_KERNEL_SIZE: 15,\n    HP_LSTMCNN_CONV2_KERNEL_SIZE: 6,\n    HP_LSTMCNN_POOL1_KERNEL_SIZE: 2,\n    HP_LSTMCNN_POOL2_KERNEL_SIZE: 4,\n    HP_LSTMCNN_DROPOUT_LSTM_RATE: 0.6,\n    HP_LSTMCNN_DROPOUT_ATTN_RATE: 0.2,\n    HP_LSTMCNN_DROPOUT_CONV1_RATE: 0.3,\n    HP_LSTMCNN_DROPOUT_CONV2_RATE: 0.3,\n    HP_LSTMCNN_DROPOUT_FC_RATE: 0.55,\n    HP_LSTMCNN_CNN_OUT_CHANNELS: 40,\n    HP_LSTMCNN_FC_HIDDEN_SIZE: 600, \n\n    HP_LSTM_HIDDEN_SIZE: 2048,\n    HP_LSTM_NUM_LAYERS: 2,\n    HP_LSTM_DROPOUT: 0.1,\n}","metadata":{"execution":{"iopub.status.busy":"2024-12-18T23:33:53.622702Z","iopub.status.idle":"2024-12-18T23:33:53.623083Z","shell.execute_reply":"2024-12-18T23:33:53.622920Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_loaders(model_type, batch_size, train_x, train_y, val_x, val_y, test_x, test_y):\n    if model_type == 'LSTM'or model_type == 'LSTMCNN' :\n        # Transpose X to match LSTM input requirements (batch_size, seq_length, input_size)\n        X_train = train_x.transpose(0, 2, 1)\n        X_val = val_x.transpose(0, 2, 1)\n        X_test = test_x.transpose(0, 2, 1)\n    elif model_type == 'CNN':\n        # For CNN, reshape to (n_samples, channels, height, width)\n        X_train = train_x[:, np.newaxis, :, :]\n        X_val = val_x[:, np.newaxis, :, :]\n        X_test = test_x[:, np.newaxis, :, :]\n    else:\n        raise ValueError(f\"Unknown model_type: {model_type}\")\n\n    y_train = train_y\n    y_val = val_y\n    y_test = test_y\n\n    print(\"Numpy Train dataset shapes:\", X_train.shape, y_train.shape)\n    print(\"Numpy Val dataset shapes:\", X_val.shape, y_val.shape)\n    print(\"Numpy Test dataset shapes:\", X_test.shape, y_test.shape)\n\n    # Convert data to PyTorch tensors\n    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n    X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n    y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n\n    # Create TensorDatasets\n    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n\n    # Print shapes of the tensors\n    print(\"X_train_tensor shape:\", train_dataset.tensors[0].shape)\n    print(\"y_train_tensor shape:\", train_dataset.tensors[1].shape)\n    print(\"X_val_tensor shape:\", val_dataset.tensors[0].shape)\n    print(\"y_val_tensor shape:\", val_dataset.tensors[1].shape)\n    print(\"X_test_tensor shape:\", test_dataset.tensors[0].shape)\n    print(\"y_test_tensor shape:\", test_dataset.tensors[1].shape)\n\n    # Print number of samples\n    print(\"Number of samples in train_dataset:\", len(train_dataset))\n    print(\"Number of samples in val_dataset:\", len(val_dataset))\n    print(\"Number of samples in test_dataset:\", len(test_dataset))\n\n    # Create DataLoaders\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n\n    # Print batch size\n    for batch_idx, (inputs, labels) in enumerate(train_loader):\n        print(f\"Batch {batch_idx + 1} - inputs shape: {inputs.shape}, labels shape: {labels.shape}\")\n        single_batch_size = inputs.shape\n        break\n    \n    return single_batch_size, train_loader, val_loader, test_loader","metadata":{"execution":{"iopub.status.busy":"2024-12-18T23:33:53.623970Z","iopub.status.idle":"2024-12-18T23:33:53.624332Z","shell.execute_reply":"2024-12-18T23:33:53.624156Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_final_loaders(model_type, batch_size, train_x, train_y, val_x, val_y):\n    if model_type == 'LSTM'or model_type == 'LSTMCNN' :\n        # Transpose X to match LSTM input requirements (batch_size, seq_length, input_size)\n        X_train = train_x.transpose(0, 2, 1)\n        X_val = val_x.transpose(0, 2, 1)\n    elif model_type == 'CNN':\n        # For CNN, reshape to (n_samples, channels, height, width)\n        X_train = train_x[:, np.newaxis, :, :]\n        X_val = val_x[:, np.newaxis, :, :]\n    else:\n        raise ValueError(f\"Unknown model_type: {model_type}\")\n\n    y_train = train_y\n    y_val = val_y\n\n    print(\"Numpy Train dataset shapes:\", X_train.shape, y_train.shape)\n    print(\"Numpy Val dataset shapes:\", X_val.shape, y_val.shape)\n\n    # Convert data to PyTorch tensors\n    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n    y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n    X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n    y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n\n    # Create TensorDatasets\n    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n\n    # Print shapes of the tensors\n    print(\"X_train_tensor shape:\", train_dataset.tensors[0].shape)\n    print(\"y_train_tensor shape:\", train_dataset.tensors[1].shape)\n    print(\"X_val_tensor shape:\", val_dataset.tensors[0].shape)\n    print(\"y_val_tensor shape:\", val_dataset.tensors[1].shape)\n\n    # Print number of samples\n    print(\"Number of samples in train_dataset:\", len(train_dataset))\n    print(\"Number of samples in val_dataset:\", len(val_dataset))\n\n    # Create DataLoaders\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n\n    # Print batch size\n    for batch_idx, (inputs, labels) in enumerate(train_loader):\n        print(f\"Batch {batch_idx + 1} - inputs shape: {inputs.shape}, labels shape: {labels.shape}\")\n        single_batch_size = inputs.shape\n        break\n    \n    return single_batch_size, train_loader, val_loader","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_private_loader(model_type, batch_size, test_x, test_y):\n    if model_type == 'LSTM'or model_type == 'LSTMCNN' :\n        # Transpose X to match LSTM input requirements (batch_size, seq_length, input_size)\n        X_test = test_x.transpose(0, 2, 1)\n    elif model_type == 'CNN':\n        # For CNN, reshape to (n_samples, channels, height, width)\n        X_test = test_x[:, np.newaxis, :, :]\n    else:\n        raise ValueError(f\"Unknown model_type: {model_type}\")\n\n    y_test = test_y\n\n    print(\"Numpy Private test dataset shapes:\", X_test.shape, y_test.shape)\n\n    # Convert data to PyTorch tensors\n    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n\n    # Create TensorDatasets\n    private_test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n\n    # Print shapes of the tensors\n    print(\"Private X_test_tensor shape:\", private_test_dataset.tensors[0].shape)\n    print(\"Private y_test_tensor shape:\", private_test_dataset.tensors[1].shape)\n\n    # Print number of samples\n    print(\"Number of samples in private_test_dataset:\", len(private_test_dataset))\n\n    # Create DataLoaders\n    private_test_loader = DataLoader(private_test_dataset, batch_size=batch_size)\n    \n    return private_test_loader","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Define models","metadata":{}},{"cell_type":"code","source":"def conv_output_size(input_size, kernel_size, stride, padding=0):\n    return (input_size - kernel_size + 2 * padding) // stride + 1\n\ndef pool_output_size(input_size, kernel_size, stride, padding=0):\n    return (input_size - kernel_size + 2 * padding) // stride + 1","metadata":{"execution":{"iopub.status.busy":"2024-12-18T23:33:53.625171Z","iopub.status.idle":"2024-12-18T23:33:53.625505Z","shell.execute_reply":"2024-12-18T23:33:53.625346Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SimpleLSTM(nn.Module):\n    def __init__(self, input_size, num_classes, hparams):\n        super(SimpleLSTM, self).__init__()\n        \n        self.hparams = hparams\n        \n        # Extract hyperparameters from hparams\n        hidden_size = hparams[HP_LSTM_HIDDEN_SIZE]\n        num_layers = hparams[HP_LSTM_NUM_LAYERS]\n        dropout = hparams[HP_LSTM_DROPOUT]\n        \n        self.description = (\n        f\"LSTM(input_size={input_size}, num_classes={num_classes}, hidden_size={hidden_size}, num_layers={num_layers}, dropout={dropout})\"\n        )\n        \n        self.lstm = nn.LSTM(\n            input_size=input_size,\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=dropout\n        )\n        self.fc = nn.Linear(hidden_size, num_classes)\n\n    def forward(self, x):\n        # x: (batch_size, seq_length, input_size)\n        out, (h_n, c_n) = self.lstm(x)  # out: (batch_size, seq_length, hidden_size)\n        out = out[:, -1, :]  # Get the output of the last time step\n        out = self.fc(out)  # out: (batch_size, num_classes)\n        return out\n","metadata":{"execution":{"iopub.status.busy":"2024-12-18T23:33:53.626177Z","iopub.status.idle":"2024-12-18T23:33:53.626418Z","shell.execute_reply":"2024-12-18T23:33:53.626322Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class LSTMAttentionCNN(nn.Module):\n    def __init__(\n        self,\n        input_size,\n        seq_length,\n        num_classes,\n        hparams\n    ):\n        super(LSTMAttentionCNN, self).__init__()\n        \n        self.hparams = hparams\n\n        num_layers = hparams[HP_LSTMCNN_NUM_LAYERS]\n        num_heads = hparams[HP_LSTMCNN_NUM_HEADS]\n        # attention embed_dim needs to be divisible by num_heads, so adjust it to match\n        hidden_size = hparams[HP_LSTMCNN_HIDDEN_SIZE] - hparams[HP_LSTMCNN_HIDDEN_SIZE] % num_heads \n        conv1_kernel_size = hparams[HP_LSTMCNN_CONV1_KERNEL_SIZE]\n        conv2_kernel_size = hparams[HP_LSTMCNN_CONV2_KERNEL_SIZE]\n        pool1_kernel_size = hparams[HP_LSTMCNN_POOL1_KERNEL_SIZE]\n        pool2_kernel_size = hparams[HP_LSTMCNN_POOL2_KERNEL_SIZE]\n        dropout_lstm_rate = hparams[HP_LSTMCNN_DROPOUT_LSTM_RATE]\n        dropout_attn_rate = hparams[HP_LSTMCNN_DROPOUT_ATTN_RATE]\n        dropout_conv1_rate = hparams[HP_LSTMCNN_DROPOUT_CONV1_RATE]\n        dropout_conv2_rate = hparams[HP_LSTMCNN_DROPOUT_CONV2_RATE]\n        dropout_fc_rate = hparams[HP_LSTMCNN_DROPOUT_FC_RATE]\n        cnn_out_channels = hparams[HP_LSTMCNN_CNN_OUT_CHANNELS]\n        fc_hidden_size = hparams[HP_LSTMCNN_FC_HIDDEN_SIZE]\n        \n        self.description = (\n        f\"LSTMAttentionCNN(input_size={input_size}, seq_length={seq_length}, \"\n        f\"hidden_size={hidden_size}, num_layers={num_layers}, num_heads={num_heads}, \"\n        f\"conv1_kernel_size={conv1_kernel_size}, conv2_kernel_size={conv2_kernel_size}, \"\n        f\"pool1_kernel_size={pool1_kernel_size}, pool2_kernel_size={pool2_kernel_size}, \"\n        f\"dropout_lstm_rate={dropout_lstm_rate}, dropout_attn_rate={dropout_attn_rate}, \"\n        f\"dropout_conv1_rate={dropout_conv1_rate}, dropout_conv2_rate={dropout_conv2_rate}, \"\n        f\"dropout_fc_rate={dropout_fc_rate}, cnn_out_channels={cnn_out_channels}, \"\n        f\"fc_hidden_size={fc_hidden_size})\"\n        )\n    \n        # LSTM layer\n        self.lstm = nn.LSTM(\n            input_size=input_size,\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout = dropout_lstm_rate\n        )\n        \n        # Dropout after LSTM\n        self.dropout_lstm = nn.Dropout(dropout_lstm_rate)\n\n        # MultiHeadAttention layer\n        self.attention = nn.MultiheadAttention(\n            embed_dim=hidden_size,\n            num_heads=num_heads,\n            batch_first=True\n        )\n\n        # Dropout after attention\n        self.dropout_attention = nn.Dropout(dropout_attn_rate)\n\n        # CNN layers using Conv1d\n        self.conv1 = nn.Conv1d(\n            in_channels=hidden_size,\n            out_channels=cnn_out_channels,\n            kernel_size=conv1_kernel_size\n        )\n        self.dropout_conv1 = nn.Dropout(dropout_conv1_rate)\n\n        self.pool1 = nn.MaxPool1d(kernel_size=pool1_kernel_size, stride=pool1_kernel_size)\n\n        self.conv2 = nn.Conv1d(\n            in_channels=cnn_out_channels,\n            out_channels=cnn_out_channels,\n            kernel_size=conv2_kernel_size\n        )\n\n        self.dropout_conv2 = nn.Dropout(dropout_conv2_rate)\n\n        self.pool2 = nn.MaxPool1d(kernel_size=pool2_kernel_size, stride=pool2_kernel_size)\n\n        length = seq_length\n\n        # After conv1\n        length = conv_output_size(length, conv1_kernel_size, stride=1)\n\n        # After pool1\n        length = pool_output_size(length, pool1_kernel_size, stride=pool1_kernel_size)\n\n        # After conv2\n        length = conv_output_size(length, conv2_kernel_size, stride=1)\n\n        # After pool2\n        length = pool_output_size(length, pool2_kernel_size, stride=pool2_kernel_size)\n\n        if length <= 0:\n            print(f'length:{length}')\n            raise ValueError(\"Negative or zero dimension size after convolution/pooling layers. Adjust your hyperparameters.\")\n\n        num_features = cnn_out_channels * length\n\n        # Fully connected layers\n        self.fc1 = nn.Linear(num_features, fc_hidden_size)\n        self.dropout_fc = nn.Dropout(dropout_fc_rate)\n        self.fc2 = nn.Linear(fc_hidden_size, num_classes)\n\n    def forward(self, x):\n        # LSTM layer\n        x, _ = self.lstm(x)\n        x = self.dropout_lstm(x)\n\n        # MultiHeadAttention layer\n        x, _ = self.attention(x, x, x)\n        x = self.dropout_attention(x)\n\n        # Prepare data for Conv1d\n        # Transpose to (batch_size, hidden_size, seq_length) for Conv1d\n        x = x.transpose(1, 2)\n\n        # CNN layers\n        x = F.relu(x)\n        x = self.conv1(x)\n        x = self.dropout_conv1(x)\n        x = self.pool1(x)\n\n        x = F.relu(x)\n        x = self.conv2(x)\n        x = self.dropout_conv2(x)\n        x = self.pool2(x)\n\n        # Flatten\n        x = x.view(x.size(0), -1)\n\n        # Fully connected layers\n        x = F.relu(x)\n        x = self.fc1(x)\n        x = self.dropout_fc(x)\n        x = self.fc2(x)\n\n        # return x\n        return F.softmax(x, dim=1)","metadata":{"execution":{"iopub.status.busy":"2024-12-18T23:33:53.627457Z","iopub.status.idle":"2024-12-18T23:33:53.627816Z","shell.execute_reply":"2024-12-18T23:33:53.627628Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CustomCNN(nn.Module):\n    def __init__(\n        self,\n        num_classes,\n        input_height,\n        input_width,\n        hparams\n    ):\n        super(CustomCNN, self).__init__()\n        \n        self.hparams = hparams\n\n        conv1_kernel_size_x = hparams[HP_CNN_CONV1_KERNEL_SIZE_X]\n        conv1_kernel_size_y = hparams[HP_CNN_CONV1_KERNEL_SIZE_Y]\n        conv2_kernel_size_x = hparams[HP_CNN_CONV2_KERNEL_SIZE_X]\n        conv2_kernel_size_y = hparams[HP_CNN_CONV2_KERNEL_SIZE_Y]\n        pool1_kernel_size_x = hparams[HP_CNN_POOL1_KERNEL_SIZE_X]\n        pool1_kernel_size_y = hparams[HP_CNN_POOL1_KERNEL_SIZE_Y]\n        pool2_kernel_size_x = hparams[HP_CNN_POOL2_KERNEL_SIZE_X]\n        pool2_kernel_size_y = hparams[HP_CNN_POOL2_KERNEL_SIZE_Y]\n        hidden_size = hparams[HP_CNN_HIDDEN_SIZE]\n        dropout_conv1_rate = hparams[HP_CNN_DROPOUT_CONV1_RATE]\n        dropout_conv2_rate = hparams[HP_CNN_DROPOUT_CONV2_RATE]\n        dropout_fc_rate = hparams[HP_CNN_DROPOUT_FC_RATE]\n        num_channels = hparams[HP_CNN_NUM_CHANNELS]\n        \n        self.description = (\n        f\"CNN(num_classes={num_classes}, input_height={input_height}, input_width={input_width}, \"\n        f\"hidden_size={hidden_size}, dropout_conv1_rate={dropout_conv1_rate}, \"\n        f\"conv1_kernel_size=({conv1_kernel_size_x}, {conv1_kernel_size_y}), conv2_kernel_size=({conv2_kernel_size_x}, {conv2_kernel_size_y}), \"\n        f\"pool1_kernel_size=({pool1_kernel_size_x}, {pool1_kernel_size_y}), pool2_kernel_size=({pool2_kernel_size_x}, {pool2_kernel_size_y}), \"\n        f\"dropout_conv2_rate={dropout_conv2_rate}, dropout_fc_rate={dropout_fc_rate}, \"\n        f\"num_channels={num_channels})\"\n        )\n        \n        # First convolutional layer\n        self.conv1 = nn.Conv2d(\n            in_channels=1,\n            out_channels=num_channels,\n            kernel_size=(conv1_kernel_size_x, conv1_kernel_size_y)\n        )\n\n        self.dropout_conv1 = nn.Dropout2d(dropout_conv1_rate)\n\n        self.pool1 = nn.MaxPool2d(\n            kernel_size=(pool1_kernel_size_x, pool1_kernel_size_y),\n            stride=(pool1_kernel_size_x, pool1_kernel_size_y)\n        )\n\n        self.conv2 = nn.Conv2d(\n            in_channels=num_channels,\n            out_channels=num_channels,\n            kernel_size=(conv2_kernel_size_x, conv2_kernel_size_y)\n        )\n\n        self.dropout_conv2 = nn.Dropout2d(dropout_conv2_rate)\n\n        self.pool2 = nn.MaxPool2d(\n            kernel_size=(pool2_kernel_size_x, pool2_kernel_size_y),\n            stride=(pool2_kernel_size_x, pool2_kernel_size_y)\n        )\n\n        # Calculate the size after convolutions and pooling\n        # Compute output dimensions step by step\n        H, W = input_height, input_width\n\n        # After conv1\n        H = conv_output_size(H, conv1_kernel_size_x, stride=1)\n        W = conv_output_size(W, conv1_kernel_size_y, stride=1)\n\n        # After pool1\n        H = pool_output_size(H, pool1_kernel_size_x, stride=pool1_kernel_size_x)\n        W = pool_output_size(W, pool1_kernel_size_y, stride=pool1_kernel_size_y)\n\n        # After conv2\n        H = conv_output_size(H, conv2_kernel_size_x, stride=1)\n        W = conv_output_size(W, conv2_kernel_size_y, stride=1)\n\n        # After pool2\n        H = pool_output_size(H, pool2_kernel_size_x, stride=pool2_kernel_size_x)\n        W = pool_output_size(W, pool2_kernel_size_y, stride=pool2_kernel_size_y)\n\n        if H <= 0 or W <= 0:\n            print(f'h:{H}, w:{W}')\n            raise ValueError(\"Negative or zero dimension size after convolution/pooling layers. \"\n                             \"Adjust your hyperparameters.\")\n\n        # Compute the number of features for the first fully connected layer\n        num_features = num_channels * H * W\n\n        # Fully connected layers\n        self.fc1 = nn.Linear(num_features, hidden_size)\n        self.dropout_fc = nn.Dropout(dropout_fc_rate)\n        self.fc2 = nn.Linear(hidden_size, num_classes)\n\n    def forward(self, x):\n        # Convolutional layer 1\n        x = self.conv1(x)\n        x = F.relu(x)\n        x = self.dropout_conv1(x)\n        x = self.pool1(x)\n\n        # Convolutional layer 2\n        x = self.conv2(x)\n        x = F.relu(x)\n        x = self.dropout_conv2(x)\n        x = self.pool2(x)\n\n        # Flatten\n        x = x.view(x.size(0), -1)\n\n        # Fully connected layers\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = self.dropout_fc(x)\n        x = self.fc2(x)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-12-18T23:33:53.628954Z","iopub.status.idle":"2024-12-18T23:33:53.629333Z","shell.execute_reply":"2024-12-18T23:33:53.629164Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Define model creation and training","metadata":{}},{"cell_type":"code","source":"def create_lstm(input_size, num_classes, hparams, device):\n    model = SimpleLSTM(\n        input_size=input_size,\n        num_classes=num_classes,\n        hparams=default_hparams | hparams\n    ).to(device)\n    return model\n\ndef create_cnn(\n    num_classes,\n    input_height,\n    input_width,\n    hparams,\n    device\n):\n    model = CustomCNN(\n        num_classes=num_classes,\n        input_height=input_height,\n        input_width=input_width,\n        hparams=default_hparams | hparams\n    ).to(device)\n\n    return model\n\ndef create_lstmcnn(\n    input_size,\n    seq_length,\n    num_classes,\n    hparams,\n    device\n):\n    model = LSTMAttentionCNN(\n        input_size=input_size,\n        seq_length=seq_length,\n        num_classes=num_classes,\n        hparams=default_hparams | hparams\n    ).to(device)\n    \n    return model\n\ndef create_sample_model(model_type, single_batch_size, num_classes, device):\n    if model_type == 'LSTM':\n        \n        # Define hyperparameters for LSTM\n        input_size = single_batch_size[2]\n\n        # Create LSTM model\n        model = create_lstm(\n            input_size=input_size,\n            num_classes=num_classes,\n            hparams=default_hparams,\n            device=device\n        )\n\n    elif model_type == 'CNN':\n        # Define hyperparameters for CNN\n        input_height = single_batch_size[2]\n        input_width = single_batch_size[3]\n\n        # Create CNN model\n        model = create_cnn(\n            num_classes=num_classes,\n            input_height=input_height,\n            input_width=input_width,\n            hparams=default_hparams,\n            device=device\n        )\n\n    elif model_type == 'LSTMCNN':\n        # Define hyperparameters for LSTMAttentionCNN\n        input_size = single_batch_size[2]\n        seq_length = single_batch_size[1]\n\n        # Create LSTMAttentionCNN model\n        model = create_lstmcnn(\n            input_size=input_size,\n            seq_length=seq_length,\n            num_classes=num_classes,\n            hparams=default_hparams,\n            device=device\n        )\n\n    else:\n        raise ValueError(f\"Unknown model_type: {model_type}\")\n        \n    display(summary(model, input_size=single_batch_size))\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2024-12-18T23:33:53.630373Z","iopub.status.idle":"2024-12-18T23:33:53.630779Z","shell.execute_reply":"2024-12-18T23:33:53.630585Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model(\n    model,\n    train_loader,\n    val_loader,\n    num_epochs=200,\n    learning_rate=0.00002,\n    save_best_model=False,\n    best_model_path='best_model.pth',\n    weight_decay=0.0,\n    log_dir=None,\n    patience=100,\n    device=None\n):      \n    # Initialize loss function\n    criterion = nn.CrossEntropyLoss()\n\n    # Initialize optimizer with optional weight decay\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n\n    # Initialize TensorBoard writer if log_dir is specified\n    if log_dir is not None:\n        writer = SummaryWriter(log_dir=log_dir)\n\n    best_val_f1 = 0.0   # For saving the best model and early stopping\n    best_val_acc = 0.0\n    epochs_without_improvement = 0  # Counter for early stopping\n\n    # Training loop\n    print(\"Starting training...\")\n    print(model.description)\n    for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0.0\n        correct_predictions = 0\n        all_labels = []\n        all_predictions = []\n\n        for inputs, labels in train_loader:\n            # Move inputs and labels to device\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            # Zero the parameter gradients\n            optimizer.zero_grad()\n\n            # Forward pass\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n            # Backward pass and optimization\n            loss.backward()\n            optimizer.step()\n\n            # Statistics\n            running_loss += loss.item() * inputs.size(0)\n            _, predicted = torch.max(outputs, 1)\n            correct_predictions += (predicted == labels).sum().item()\n            all_labels.extend(labels.cpu().numpy())\n            all_predictions.extend(predicted.cpu().numpy())\n\n        # Calculate average loss, accuracy, and F1 score for the epoch\n        epoch_loss = running_loss / len(train_loader.dataset)\n        epoch_acc = correct_predictions / len(train_loader.dataset)\n        epoch_f1 = f1_score(all_labels, all_predictions, average='macro')\n\n        # Validation phase\n        model.eval()\n        val_running_loss = 0.0\n        val_correct_predictions = 0\n        val_all_labels = []\n        val_all_predictions = []\n\n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                # Move inputs and labels to device\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n\n                val_running_loss += loss.item() * inputs.size(0)\n                _, predicted = torch.max(outputs, 1)\n                val_correct_predictions += (predicted == labels).sum().item()\n                val_all_labels.extend(labels.cpu().numpy())\n                val_all_predictions.extend(predicted.cpu().numpy())\n\n        val_loss = val_running_loss / len(val_loader.dataset)\n        val_acc = val_correct_predictions / len(val_loader.dataset)\n        val_f1 = f1_score(val_all_labels, val_all_predictions, average='macro')\n\n        # Print epoch stats\n        print(\n            f\"Epoch [{epoch + 1}/{num_epochs}] \"\n            f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}, Train F1: {epoch_f1:.4f} \"\n            f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\"\n        )\n\n        # Save the best model if specified\n        if val_f1 > best_val_f1:\n            best_val_f1 = val_f1\n            best_val_acc = val_acc\n            epochs_without_improvement = 0  # Reset the counter\n            if save_best_model:\n                torch.save(model.state_dict(), best_model_path)\n                print(f\"Best model saved with val_f1: {val_f1:.4f}\")\n        else:\n            epochs_without_improvement += 1\n        \n        # Log to TensorBoard\n        if log_dir is not None:\n            writer.add_scalar('Loss/train', epoch_loss, epoch)\n            writer.add_scalar('Accuracy/train', epoch_acc, epoch)\n            writer.add_scalar('F1/train', epoch_f1, epoch)\n            writer.add_scalar('Loss/val', val_loss, epoch)\n            writer.add_scalar('Accuracy/val', val_acc, epoch)\n            writer.add_scalar('F1/val', val_f1, epoch)\n            # Log learning rate\n            current_lr = optimizer.param_groups[0]['lr']\n            writer.add_scalar('Learning Rate', current_lr, epoch)\n\n        if epochs_without_improvement >= patience:\n            print(f\"Early stopping triggered after {patience} epochs without improvement.\")\n            break\n\n    if log_dir is not None:\n        # Log hparams\n        hparam_metrics = {\n            'hparam/val_acc': best_val_acc,\n            'hparam/val_f1': best_val_f1\n        }\n        writer.add_hparams({str(k.name): v for k, v in model.hparams.items()}, hparam_metrics)\n        writer.close()\n    print(\"Training completed.\")\n    return best_val_f1","metadata":{"execution":{"iopub.status.busy":"2024-12-18T23:33:53.631834Z","iopub.status.idle":"2024-12-18T23:33:53.632211Z","shell.execute_reply":"2024-12-18T23:33:53.632040Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Run hyperparameter search","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE_REDUCTION_ATTEMPTS = 8\nBATCH_SIZE = 256\nWEIGHT_DECAY_MIN = 0\nWEIGHT_DECAY_MAX = 1e-2\nLR_MIN = 1e-5\nLR_MAX = 0.001\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n\ndef objective(trial, function):\n    batch_size = BATCH_SIZE\n    \n    for _ in range(BATCH_SIZE_REDUCTION_ATTEMPTS):\n        try:\n            return function(batch_size, trial)\n        except RuntimeError as e:\n            if 'out of memory' in str(e).lower():\n                print(f\"Out of memory error encountered. Reducing batch size from {batch_size} to {batch_size // 2}.\")\n                torch.cuda.empty_cache()\n                batch_size = batch_size // 2\n            else:\n                # Re-raise any other RuntimeError exceptions\n                raise e\n\n    print(\"Not enough memory!\")\n    return 0\n    \n\ndef lstm_iteration(batch_size, trial):\n    model_type = 'LSTM'\n    gc.collect()\n    torch.cuda.empty_cache()\n    print(f'\\n\\nStarting iteration with batch_size={batch_size}\\n\\n')\n    single_batch_size, train_loader, val_loader, test_loader = create_loaders(model_type, batch_size, train_x, train_y, val_x, val_y, test_x, test_y)\n\n    hidden_size = trial.suggest_int(\n        \"lstm_hidden_size\",\n        HP_LSTM_HIDDEN_SIZE.domain.min_value,\n        HP_LSTM_HIDDEN_SIZE.domain.max_value\n    )\n    num_layers = trial.suggest_int(\n        \"lstm_num_layers\",\n        HP_LSTM_NUM_LAYERS.domain.min_value,\n        HP_LSTM_NUM_LAYERS.domain.max_value\n    )\n    dropout = trial.suggest_float(\n        \"lstm_dropout\",\n        HP_LSTM_DROPOUT.domain.min_value,\n        HP_LSTM_DROPOUT.domain.max_value\n    )\n\n    learning_rate = trial.suggest_float(\"learning_rate\", LR_MIN, LR_MAX)\n    weight_decay = trial.suggest_float(\"weight_decay\", WEIGHT_DECAY_MIN, WEIGHT_DECAY_MAX)\n    # Define hyperparameters\n    hparams = {\n        HP_LSTM_HIDDEN_SIZE: hidden_size,\n        HP_LSTM_NUM_LAYERS: num_layers,\n        HP_LSTM_DROPOUT: dropout\n    }\n\n    input_size = single_batch_size[2]\n\n    model = create_lstm(input_size, len(classes), hparams, device)\n    f1 = train_model(\n        model,\n        train_loader,\n        val_loader,\n        num_epochs=200,\n        learning_rate=learning_rate,\n        save_best_model=False,\n        weight_decay=weight_decay,\n        log_dir='logs_lstm',\n        device=device\n    )\n\n    return f1\n\ndef objective_lstm(trial):\n    return objective(trial, lstm_iteration)\n    \n    \ndef cnn_iteration(batch_size, trial):\n    model_type = 'CNN'\n    gc.collect()\n    torch.cuda.empty_cache()\n    print(f'\\n\\nStarting iteration with batch_size={batch_size}\\n\\n')\n    single_batch_size, train_loader, val_loader, test_loader = create_loaders(model_type, batch_size, train_x, train_y, val_x, val_y, test_x, test_y)\n\n    conv1_kernel_size_x = trial.suggest_int(\n        \"conv1_kernel_size_x\",\n        HP_CNN_CONV1_KERNEL_SIZE_X.domain.min_value,\n        HP_CNN_CONV1_KERNEL_SIZE_X.domain.max_value,\n    )\n    conv1_kernel_size_y = trial.suggest_int(\n        \"conv1_kernel_size_y\",\n        HP_CNN_CONV1_KERNEL_SIZE_Y.domain.min_value,\n        HP_CNN_CONV1_KERNEL_SIZE_Y.domain.max_value,\n    )\n    conv2_kernel_size_x = trial.suggest_int(\n        \"conv2_kernel_size_x\",\n        HP_CNN_CONV2_KERNEL_SIZE_X.domain.min_value,\n        HP_CNN_CONV2_KERNEL_SIZE_X.domain.max_value,\n    )\n    conv2_kernel_size_y = trial.suggest_int(\n        \"conv2_kernel_size_y\",\n        HP_CNN_CONV2_KERNEL_SIZE_Y.domain.min_value,\n        HP_CNN_CONV2_KERNEL_SIZE_Y.domain.max_value,\n    )\n    pool1_kernel_size_x = trial.suggest_int(\n        \"pool1_kernel_size_x\",\n        HP_CNN_POOL1_KERNEL_SIZE_X.domain.min_value,\n        HP_CNN_POOL1_KERNEL_SIZE_X.domain.max_value,\n    )\n    pool1_kernel_size_y = trial.suggest_int(\n        \"pool1_kernel_size_y\",\n        HP_CNN_POOL1_KERNEL_SIZE_Y.domain.min_value,\n        HP_CNN_POOL1_KERNEL_SIZE_Y.domain.max_value,\n    )\n    pool2_kernel_size_x = trial.suggest_int(\n        \"pool2_kernel_size_x\",\n        HP_CNN_POOL2_KERNEL_SIZE_X.domain.min_value,\n        HP_CNN_POOL2_KERNEL_SIZE_X.domain.max_value,\n    )\n    pool2_kernel_size_y = trial.suggest_int(\n        \"pool2_kernel_size_y\",\n        HP_CNN_POOL2_KERNEL_SIZE_Y.domain.min_value,\n        HP_CNN_POOL2_KERNEL_SIZE_Y.domain.max_value,\n    )\n    hidden_size = trial.suggest_int(\n        \"hidden_size\",\n        HP_CNN_HIDDEN_SIZE.domain.min_value,\n        HP_CNN_HIDDEN_SIZE.domain.max_value,\n    )\n    dropout_conv1_rate = trial.suggest_float(\n        \"dropout_conv1_rate\",\n        HP_CNN_DROPOUT_CONV1_RATE.domain.min_value,\n        HP_CNN_DROPOUT_CONV1_RATE.domain.max_value,\n    )\n    dropout_conv2_rate = trial.suggest_float(\n        \"dropout_conv2_rate\",\n        HP_CNN_DROPOUT_CONV2_RATE.domain.min_value,\n        HP_CNN_DROPOUT_CONV2_RATE.domain.max_value,\n    )\n    dropout_fc_rate = trial.suggest_float(\n        \"dropout_fc_rate\",\n        HP_CNN_DROPOUT_FC_RATE.domain.min_value,\n        HP_CNN_DROPOUT_FC_RATE.domain.max_value,\n    )\n    num_channels = trial.suggest_int(\n        \"num_channels\",\n        HP_CNN_NUM_CHANNELS.domain.min_value,\n        HP_CNN_NUM_CHANNELS.domain.max_value,\n    )\n\n    learning_rate = trial.suggest_float(\"learning_rate\", LR_MIN, LR_MAX)\n    weight_decay = trial.suggest_float(\"weight_decay\", WEIGHT_DECAY_MIN, WEIGHT_DECAY_MAX)\n    # Define hyperparameters\n    hparams = {\n        HP_CNN_CONV1_KERNEL_SIZE_X: conv1_kernel_size_x,\n        HP_CNN_CONV1_KERNEL_SIZE_Y: conv1_kernel_size_y,\n        HP_CNN_CONV2_KERNEL_SIZE_X: conv2_kernel_size_x,\n        HP_CNN_CONV2_KERNEL_SIZE_Y: conv2_kernel_size_y,\n        HP_CNN_POOL1_KERNEL_SIZE_X: pool1_kernel_size_x,\n        HP_CNN_POOL1_KERNEL_SIZE_Y: pool1_kernel_size_y,\n        HP_CNN_POOL2_KERNEL_SIZE_X: pool2_kernel_size_x,\n        HP_CNN_POOL2_KERNEL_SIZE_Y: pool2_kernel_size_y,\n        HP_CNN_HIDDEN_SIZE: hidden_size,\n        HP_CNN_DROPOUT_CONV1_RATE: dropout_conv1_rate,\n        HP_CNN_DROPOUT_CONV2_RATE: dropout_conv2_rate,\n        HP_CNN_DROPOUT_FC_RATE: dropout_fc_rate,\n        HP_CNN_NUM_CHANNELS: num_channels,\n    }\n    \n    input_height = single_batch_size[2]\n    input_width = single_batch_size[3]\n    \n    model = create_cnn(len(classes), input_height, input_width, hparams, device)\n    f1 = train_model(\n        model,\n        train_loader,\n        val_loader,\n        num_epochs=200,\n        learning_rate=learning_rate,\n        save_best_model=False,\n        weight_decay=weight_decay,\n        log_dir='logs_cnn',\n        device=device\n    )\n\n    return f1\n\ndef objective_cnn(trial):\n    return objective(trial, cnn_iteration)\n    \n    \ndef lstmcnn_iteration(batch_size, trial):\n    model_type = 'LSTMCNN'\n    gc.collect()\n    torch.cuda.empty_cache()\n    print(f'\\n\\nStarting iteration with batch_size={batch_size}\\n\\n')\n    single_batch_size, train_loader, val_loader, test_loader = create_loaders(model_type, batch_size, train_x, train_y, val_x, val_y, test_x, test_y)\n\n    hidden_size = trial.suggest_int(\n        \"hidden_size\",\n        HP_LSTMCNN_HIDDEN_SIZE.domain.min_value,\n        HP_LSTMCNN_HIDDEN_SIZE.domain.max_value,\n    )\n    num_layers = trial.suggest_int(\n        \"num_layers\",\n        HP_LSTMCNN_NUM_LAYERS.domain.min_value,\n        HP_LSTMCNN_NUM_LAYERS.domain.max_value,\n    )\n    num_heads = trial.suggest_int(\n        \"num_heads\",\n        HP_LSTMCNN_NUM_HEADS.domain.min_value,\n        HP_LSTMCNN_NUM_HEADS.domain.max_value,\n    )\n    conv1_kernel_size = trial.suggest_int(\n        \"conv1_kernel_size\",\n        HP_LSTMCNN_CONV1_KERNEL_SIZE.domain.min_value,\n        HP_LSTMCNN_CONV1_KERNEL_SIZE.domain.max_value,\n    )\n    conv2_kernel_size = trial.suggest_int(\n        \"conv2_kernel_size\",\n        HP_LSTMCNN_CONV2_KERNEL_SIZE.domain.min_value,\n        HP_LSTMCNN_CONV2_KERNEL_SIZE.domain.max_value,\n    )\n    pool1_kernel_size = trial.suggest_int(\n        \"pool1_kernel_size\",\n        HP_LSTMCNN_POOL1_KERNEL_SIZE.domain.min_value,\n        HP_LSTMCNN_POOL1_KERNEL_SIZE.domain.max_value,\n    )\n    pool2_kernel_size = trial.suggest_int(\n        \"pool2_kernel_size\",\n        HP_LSTMCNN_POOL2_KERNEL_SIZE.domain.min_value,\n        HP_LSTMCNN_POOL2_KERNEL_SIZE.domain.max_value,\n    )\n    dropout_lstm_rate = trial.suggest_float(\n        \"dropout_lstm_rate\",\n        HP_LSTMCNN_DROPOUT_LSTM_RATE.domain.min_value,\n        HP_LSTMCNN_DROPOUT_LSTM_RATE.domain.max_value,\n    )\n    dropout_attn_rate = trial.suggest_float(\n        \"dropout_attn_rate\",\n        HP_LSTMCNN_DROPOUT_ATTN_RATE.domain.min_value,\n        HP_LSTMCNN_DROPOUT_ATTN_RATE.domain.max_value,\n    )\n    dropout_conv1_rate = trial.suggest_float(\n        \"dropout_conv1_rate\",\n        HP_LSTMCNN_DROPOUT_CONV1_RATE.domain.min_value,\n        HP_LSTMCNN_DROPOUT_CONV1_RATE.domain.max_value,\n    )\n    dropout_conv2_rate = trial.suggest_float(\n        \"dropout_conv2_rate\",\n        HP_LSTMCNN_DROPOUT_CONV2_RATE.domain.min_value,\n        HP_LSTMCNN_DROPOUT_CONV2_RATE.domain.max_value,\n    )\n    dropout_fc_rate = trial.suggest_float(\n        \"dropout_fc_rate\",\n        HP_LSTMCNN_DROPOUT_FC_RATE.domain.min_value,\n        HP_LSTMCNN_DROPOUT_FC_RATE.domain.max_value,\n    )\n    cnn_out_channels = trial.suggest_int(\n        \"cnn_out_channels\",\n        HP_LSTMCNN_CNN_OUT_CHANNELS.domain.min_value,\n        HP_LSTMCNN_CNN_OUT_CHANNELS.domain.max_value,\n    )\n    fc_hidden_size = trial.suggest_int(\n        \"fc_hidden_size\",\n        HP_LSTMCNN_FC_HIDDEN_SIZE.domain.min_value,\n        HP_LSTMCNN_FC_HIDDEN_SIZE.domain.max_value,\n    )\n\n    learning_rate = trial.suggest_float(\"learning_rate\", LR_MIN, LR_MAX)\n    weight_decay = trial.suggest_float(\"weight_decay\", WEIGHT_DECAY_MIN, WEIGHT_DECAY_MAX)\n    # Define hyperparameters\n    hparams = {\n        HP_LSTMCNN_HIDDEN_SIZE: hidden_size,\n        HP_LSTMCNN_NUM_LAYERS: num_layers,\n        HP_LSTMCNN_NUM_HEADS: num_heads,\n        HP_LSTMCNN_CONV1_KERNEL_SIZE: conv1_kernel_size,\n        HP_LSTMCNN_CONV2_KERNEL_SIZE: conv2_kernel_size,\n        HP_LSTMCNN_POOL1_KERNEL_SIZE: pool1_kernel_size,\n        HP_LSTMCNN_POOL2_KERNEL_SIZE: pool2_kernel_size,\n        HP_LSTMCNN_DROPOUT_LSTM_RATE: dropout_lstm_rate,\n        HP_LSTMCNN_DROPOUT_ATTN_RATE: dropout_attn_rate,\n        HP_LSTMCNN_DROPOUT_CONV1_RATE: dropout_conv1_rate,\n        HP_LSTMCNN_DROPOUT_CONV2_RATE: dropout_conv2_rate,\n        HP_LSTMCNN_DROPOUT_FC_RATE: dropout_fc_rate,\n        HP_LSTMCNN_CNN_OUT_CHANNELS: cnn_out_channels,\n        HP_LSTMCNN_FC_HIDDEN_SIZE: fc_hidden_size,\n    }\n\n    input_size = single_batch_size[2]\n    seq_length = single_batch_size[1]\n    \n    model = create_lstmcnn(input_size, seq_length, len(classes), hparams, device)\n    f1 = train_model(\n        model,\n        train_loader,\n        val_loader,\n        num_epochs=200,\n        learning_rate=learning_rate,\n        save_best_model=False,\n        weight_decay=weight_decay,\n        log_dir='logs_lstmcnn',\n        device=device\n    )\n\n    return f1\n\ndef objective_lstmcnn(trial):\n    return objective(trial, lstmcnn_iteration)","metadata":{"execution":{"iopub.status.busy":"2024-12-18T23:33:53.634196Z","iopub.status.idle":"2024-12-18T23:33:53.634569Z","shell.execute_reply":"2024-12-18T23:33:53.634406Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if MODE == 'SEARCH':\n    # study_cnn = optuna.create_study(direction=\"maximize\")\n    # study_cnn.optimize(objective_cnn, n_trials=200, n_jobs=1)\n\n    # print(\"Best hyperparameters for CNN:\", study_cnn.best_params)\n    \n    study_lstmcnn = optuna.create_study(direction=\"maximize\")\n    study_lstmcnn.optimize(objective_lstmcnn, n_trials=200, n_jobs=1)\n    \n    print(\"Best hyperparameters for LSTMCNN:\", study_lstmcnn.best_params)\n    \n    # study_lstm = optuna.create_study(direction=\"maximize\")\n    # study_lstm.optimize(objective_lstm, n_trials=50, n_jobs=1)\n\n    # print(\"Best hyperparameters for LSTM:\", study_lstm.best_params)\n    \n    # print(f\"Hyperparameter search for all models done. Found values:\\n CNN ({study_cnn.best_value}): {study_cnn.best_params}\\n LSTMCNN ({study_lstmcnn.best_value}): {study_lstmcnn.best_params}\\n LSTM ({study_lstm.best_value}): {study_lstm.best_params}\")\n    # print(f\"Hyperparameter search for all models done. Found values:\\n LSTMCNN ({study_lstmcnn.best_value}): {study_lstmcnn.best_params}\\n LSTM ({study_lstm.best_value}): {study_lstm.best_params}\")\n\n    ","metadata":{"execution":{"iopub.status.busy":"2024-12-18T23:33:53.635550Z","iopub.status.idle":"2024-12-18T23:33:53.635942Z","shell.execute_reply":"2024-12-18T23:33:53.635778Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Run training for single model","metadata":{}},{"cell_type":"code","source":"def evaluate(model, device,  loader, description):\n    model.eval()\n    running_loss = 0.0\n    correct_predictions = 0\n    all_labels = []\n    all_predictions = []\n    criterion = nn.CrossEntropyLoss()\n    with torch.no_grad():\n        for inputs, labels in loader:\n            # Move inputs and labels to device\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n            running_loss += loss.item() * inputs.size(0)\n            _, predicted = torch.max(outputs, 1)\n            correct_predictions += (predicted == labels).sum().item()\n            all_labels.extend(labels.cpu().numpy())\n            all_predictions.extend(predicted.cpu().numpy())\n\n    loss = running_loss / len(loader.dataset)\n    acc = correct_predictions / len(loader.dataset)\n    f1 = f1_score(all_labels, all_predictions, average='macro')\n\n    print(f\"{description} Loss: {loss:.4f}, {description} Acc: {acc:.4f}, {description} F1: {f1:.4f}\")\n\n    # Create confusion matrix\n    class_names = [name for name, value in sorted(class_dict.items(), key=lambda x: x[1])]\n    conf_matrix = confusion_matrix(all_labels, all_predictions, labels=list(class_dict.values()))\n\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n    plt.xlabel('Predicted Labels')\n    plt.ylabel('True Labels')\n    plt.title(f\"{description} Confusion Matrix\")\n    plt.show()\n\n    return loss, acc, f1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gc.collect()\ntorch.cuda.empty_cache()\ndef test_model(model_type='CNN'):\n    BATCH_SIZE = 256\n    best_model_path = f'best_model_{model_type}.pth'\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(\"Using device:\", device)\n\n    private_test_loader = create_private_loader(model_type, BATCH_SIZE, private_test_x, private_test_y)\n    single_batch_size, train_loader, val_loader, test_loader = create_loaders(model_type, BATCH_SIZE, train_x, train_y, val_x, val_y, test_x, test_y)\n\n    model = create_sample_model(model_type, single_batch_size, len(classes), device)\n\n    train_model(\n        model,\n        train_loader,\n        val_loader,\n        num_epochs=1000,\n        learning_rate=0.00002,\n        save_best_model=True,\n        best_model_path= best_model_path,\n        weight_decay=0.02,\n        log_dir=f'{model_type}_logs',\n        device=device\n    )\n\n    model.load_state_dict(torch.load(best_model_path))\n    print(\"Loaded best model for testing.\")\n\n    print(\"Evaluating on test set:\")\n    test_loss, test_acc, test_f1 = evaluate(model, device, test_loader, \"Test\")\n\n    # Evaluation on private test set\n    print(\"Evaluating on private test set:\")\n    private_test_loss, private_test_acc, private_test_f1 = evaluate(model, device, private_test_loader, \"Private Test\")\n    \nif MODE == 'RUN':\n    test_model('CNN')\n    # test_model('LSTMCNN')","metadata":{"execution":{"iopub.status.busy":"2024-12-18T23:33:53.636917Z","iopub.status.idle":"2024-12-18T23:33:53.637281Z","shell.execute_reply":"2024-12-18T23:33:53.637119Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_final_model(model_type='CNN'):\n    BATCH_SIZE = 256\n    best_model_path = f'final_model_{model_type}.pth'\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(\"Using device:\", device)\n\n    private_test_loader = create_private_loader(model_type, BATCH_SIZE, private_test_x, private_test_y)\n    single_batch_size, final_train_loader, final_val_loader = create_final_loaders(model_type, BATCH_SIZE, final_train_x, final_train_y, val_x, val_y)\n    \n    model = create_sample_model(model_type, single_batch_size, len(classes), device)\n\n    train_model(\n        model,\n        final_train_loader,\n        final_val_loader,\n        num_epochs=1000,\n        learning_rate=0.00002,\n        save_best_model=True,\n        best_model_path= best_model_path,\n        weight_decay=0.02,\n        log_dir=f'{model_type}_final_logs',\n        device=device\n    )\n\n    model.load_state_dict(torch.load(best_model_path))\n    print(\"Loaded best model for testing.\")\n\n    print(\"Evaluating on private test set:\")\n    private_test_loss, private_test_acc, private_test_f1 = evaluate(model, device, private_test_loader, \"Private Test\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_final_model()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !zip -r tensorboard_logs1.zip ./logs","metadata":{"execution":{"iopub.status.busy":"2024-12-18T23:33:53.638017Z","iopub.status.idle":"2024-12-18T23:33:53.638383Z","shell.execute_reply":"2024-12-18T23:33:53.638224Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"gc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-12-18T23:33:53.639349Z","iopub.status.idle":"2024-12-18T23:33:53.639741Z","shell.execute_reply":"2024-12-18T23:33:53.639551Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !rm -rf ./logs*\n# !rm tensorboard*","metadata":{"execution":{"iopub.status.busy":"2024-12-18T23:33:53.640411Z","iopub.status.idle":"2024-12-18T23:33:53.640809Z","shell.execute_reply":"2024-12-18T23:33:53.640614Z"},"trusted":true},"outputs":[],"execution_count":null}]}